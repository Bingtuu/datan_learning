{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#机器学习流程（The-Machine-Learning-Pipeline）\" data-toc-modified-id=\"机器学习流程（The-Machine-Learning-Pipeline）-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>机器学习流程（The Machine Learning Pipeline）</a></span></li><li><span><a href=\"#数值型特征的处理（Fancy-Tricks-with-Simple-Numbers）\" data-toc-modified-id=\"数值型特征的处理（Fancy-Tricks-with-Simple-Numbers）-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>数值型特征的处理（Fancy Tricks with Simple Numbers）</a></span><ul class=\"toc-item\"><li><span><a href=\"#对数值型特征的检查\" data-toc-modified-id=\"对数值型特征的检查-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>对数值型特征的检查</a></span></li><li><span><a href=\"#特征构成的空间\" data-toc-modified-id=\"特征构成的空间-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>特征构成的空间</a></span></li><li><span><a href=\"#计数特征的处理\" data-toc-modified-id=\"计数特征的处理-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>计数特征的处理</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  机器学习流程（The Machine Learning Pipeline）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A **mathematical model** of data describes the relationships between different aspects of the data.\n",
    "* A **feature** is a **numeric representation** of raw data. There are many ways to turn raw data into numeric measurements, which is why features can end up looking like a lot of things. Naturally, features must derive from the type of data that is available.\n",
    "\n",
    "Feature engineering is the process of formulating the most appropriate features given the data, the model, and the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and models sit between raw data and the desired insights. In a machine learning workflow, we pick not only the model, but also the features. This is a double-jointed lever, and the choice of one affects the other. Good features make the subsequent modeling step easy and the resulting model more capable of completing the desired task. Bad features may require a much more complicated model to achieve the same level of performance.\n",
    "\n",
    "![pipeline](pics\\pipeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数值型特征的处理（Fancy Tricks with Simple Numbers）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  对数值型特征的检查"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* whether the magnitude matters\n",
    "> This sanity check is particularly important for automatically accrued numbers such as counts\n",
    "\n",
    "* the scale of the features, the largest and the smallest values, do they span several orders of magnitude?\n",
    "> $k$-means clustering, nearest neighbors methods, radial basis function (RBF) kernels, and anything that uses the Euclidean distance. For these models and modeling components, it is often a good idea to normalize the features so that the output stays on an expected scale. \n",
    "\n",
    "* the distribution of numeric features, distribution summarizes the probability of taking on a particular value\n",
    "> the training process of a linear regression model assumes that prediction errors are distributed like a Gaussian.Except when the prediction target spreads out over several orders of magnitude. In this case, the Gaussian error assumption likely no longer holds. One way to deal with this is to transform the output target in order to tame the magnitude of the growth. (this would be target engineering) Log transforms, which are a type of power transform, take the distribution of the variable closer to Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  特征构成的空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the vast majority of machine learning applications, the input to a model is usually represented as a numeric vector.A vector can be visualized as a point in space.  \n",
    "In the world of data, an abstract vector and its feature dimensions take on actual meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 计数特征的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data can be produced at high volume and velocity, it’s very likely to contain a few extreme values. **It is a good idea to check the scale and determine whether to keep the data as raw numbers**, convert them into **binary values** to indicate presence, or **bin them into coarser granularity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*在计数特征的处理方面，书中主要讲了二值化和分箱（区间量化）两个方法；二值化的示例中，由于歌曲收听次数并不是衡量用户喜好的**强壮**指标，因此采用二值化的方法；数据分箱的案例中，商家点评数量跨了若干数量级，而过大的离散值会对算法的度量指标造成破坏作用，因此将点评数量分到多个箱子里面，去掉实际的计数值。  \n",
    "区间量化将连续型的数值映射为离散型数值，可以将这种离散型数值看作是一种有序的分享序列，表示的是对密度的测量。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
